we have Matrix<T> + int, we need int + Matrix<T> (DONE)
we have Matrix<T> - int, we need int - Matrix<T> (DONE)
we have Matrix<T> * int, we need int * Matrix<T> (DONE)
we have Matrix<T> / int, we need int / Matrix<T> (DONE)

Make dot function (DONE)

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


Finish comments for Matrix<T> methods

Layer members (DONE??????????)
Layer act(const Matrix<T>&)     // chooses activation based on layer.activation, and applies activation
layer d_act(const Matrix<T>&)   // based on layer.activation, get the derivative and apply to input

k_folds_cv:   // Do this // do this later lol


Model: 
    loss (DONE)
    train (DONE)


/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


    